"""
Emotion Recognition - Vision-Frame-Based Face Channel
More information about the implementation of the model:
Barros, P., & Wermter, S. (2016). Developing crossmodal expression recognition based on a deep neural model. Adaptive behavior, 24(5), 373-396.
http://journals.sagepub.com/doi/full/10.1177/1059712316664017
"""

import numpy
import cv2
import modelLoader
import modelDictionary
import imageProcessingUtil
import GUIController
import sys


finalImageSize = (1024,768) # Size of the final image generated by the demo
categoricalInitialPosition = 260 # Initial position for adding the categorical graph in the final image
faceSize = (64,64) # Input size for both models: categorical and dimensional
faceDetectionMaximumFrequency = 10 # Frequency that a face will be detected: every X frames.

modelCategorical = modelLoader.modelLoader(modelDictionary.CategoricaModel)
modelDimensional = modelLoader.modelLoader(modelDictionary.DimensionalModel)

imageProcessing = imageProcessingUtil.imageProcessingUtil(faceDetectionMaximumFrequency)

GUIController = GUIController.GUIController()

cv2.namedWindow("Visual Emotion Recognition")

cap = cv2.VideoCapture(0)
#cap.open(0)

if cap.isOpened():  # try to get the first frame
    rval, f = cap.read()
    #   rval2, f2 = vc2.read()
else:
    rval = False

print ("Rval:", rval)

while(True):
    # Capture frame-by-frame
        rval, frame = cap.read()

        facePoints, face = imageProcessing.detectFace(frame)
        print ("Print:", len(face))

        image = numpy.zeros((finalImageSize[1], finalImageSize[0], 3), numpy.uint8)
        image[0:480, 0:640] = frame
        frame = image

        if not len(face) == 0:
            face = imageProcessing.preProcess(face, faceSize)
            categoricalRecognition = modelCategorical.classify(face)
            dimensionalRecognition = modelDimensional.classify(face)

            frame = GUIController.createDetectedFacGUI(frame,facePoints,modelCategorical.modelDictionary, categoricalRecognition)
            frame = GUIController.createDimensionalEmotionGUI(dimensionalRecognition, frame, categoricalRecognition, modelCategorical.modelDictionary)
            frame =  GUIController.createCategoricalEmotionGUI(categoricalRecognition,frame,modelCategorical.modelDictionary, initialPosition=categoricalInitialPosition)

        # Display the resulting frame
        cv2.imshow('frame',frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

# When everything done, release the capture
cap.release()
cv2.destroyAllWindows()